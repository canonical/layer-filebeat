"options":
  "extra_packages":
    "description": "Space separated list of extra deb packages to install.\n"
    "type": "string"
    "default": ""
  "package_status":
    "default": "install"
    "type": "string"
    "description": "The status of service-affecting packages will be set to this value\
      \ in the dpkg database. Valid values are \"install\" and \"hold\".\n"
  "install_sources":
    "description": "apt repository to fetch beats from"
    "type": "string"
    "default": "deb http://packages.elastic.co/beats/apt stable main"
  "install_keys":
    "description": "repository key"
    "type": "string"
    "default": "D88E42B4"
  "logpath":
    "type": "string"
    "default": "/var/log/*.log /var/log/*/*.log"
    "description": "Space separated log paths to monitor. Can contain wildcards."
  "logging_to_syslog":
    "type": "boolean"
    "description": "Send filebeat logs to syslog https://www.elastic.co/guide/en/beats/filebeat/master/configuration-logging.html#_literal_to_syslog_literal"
    "default": !!bool "true"
  "logstash_hosts":
    "type": "string"
    "default": ""
    "description": "A comma separated list of logstash output hosts in addition to\
      \ those from relations."
  "logstash_ssl_cert":
    "type": "string"
    "default": ""
    "description": "Public SSL certificate data for connecting securely to logstash."
  "logstash_ssl_key":
    "type": "string"
    "default": ""
    "description": "Private SSL key data for connecting security to logstash."
  "kafka_hosts":
    "type": "string"
    "default": ""
    "description": "A comma separated list of kafka output hosts in addition to those\
      \ from relations."
  "kafka_topic":
    "type": "string"
    "default": "%{[type]}"
    "description": "Topic name. Format strings are allowed. https://www.elastic.co/guide/en/beats/filebeat/master/kafka-output.html#_literal_topic_literal"
  "kafka_topics":
    "type": "string"
    "default": ""
    "description": "Expert setting topics filter. https://www.elastic.co/guide/en/beats/filebeat/master/kafka-output.html#_literal_topics_literal"
  "harvester_buffer_size":
    "type": "int"
    "default": !!int "16384"
    "description": "Defines the buffer size every harvester uses when fetching the\
      \ file"
  "max_bytes":
    "type": "int"
    "default": !!int "10485760"
    "description": "Maximum number of bytes a single log event can have. Default 10MB"
  "exclude_files":
    "type": "string"
    "default": "[\".gz$\"]"
    "description": "A list of regular expressions to match the files that you want\
      \ Filebeat to ignore. https://www.elastic.co/guide/en/beats/filebeat/5.3/configuration-filebeat-options.html#exclude-files"
  "exclude_lines":
    "type": "string"
    "default": "[]"
    "description": "A list of regular expressions to match the lines that you want\
      \ Filebeat to exclude. https://www.elastic.co/guide/en/beats/filebeat/5.3/configuration-filebeat-options.html#exclude-lines"
  "fields":
    "type": "string"
    "default": ""
    "description": "Space seperated list of key:value that the prospector will assign\
      \ as field to each beat"
  "kube_logs":
    "type": "boolean"
    "default": !!bool "false"
    "description": "Add a prospector to ship logs from Kubernetes pods"
